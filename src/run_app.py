from pathlib import Path
import time
import streamlit as st
from faster_whisper import WhisperModel
from utils.cuda_checker import check_cuda


def save_uploaded_file(uploaded_file):
    # specify the directory
    dir_path = Path('../media')
    dir_path.mkdir(parents=True, exist_ok=True)  # create directory if it does not exist

    # create a path object for the file
    file_path = dir_path / uploaded_file.name

    # write the file
    with file_path.open("wb") as f:
        f.write(uploaded_file.getbuffer())

    st.toast(f"Saved file: {file_path}")

    return file_path


st.markdown('### üìñ –ò—Ç–æ–≥–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç –≥—Ä—É–ø–ø—ã 1.12')

uploaded_file = st.file_uploader('üîΩ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞',
                                 type=['mp3', 'wav', 'mp4', 'webm'])

if uploaded_file is not None:
    uploaded_file_path = save_uploaded_file(uploaded_file)
    time_start = time.time()

    with st.spinner('üöö –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å. –ú–∏–Ω—É—Ç–∫—É...'):
        if check_cuda():
            selected_model_path = '../models/large-v3/'
            local_device = 'cuda'
            selected_compute_type = 'int8_float16'
            st.toast(body='–û–±–Ω–∞—Ä—É–∂–µ–Ω GPU. –ë—É–¥–µ—Ç —É—Å–∫–æ—Ä—è—Ç—å—Å—è!',
                     icon='üöÄ')
        else:
            selected_model_path = '../models/medium/'
            local_device = 'cpu'
            selected_compute_type = 'int8'
            st.toast(body='–û–±–Ω–∞—Ä—É–∂–µ–Ω CPU. –ü—Ä–∏–¥—ë—Ç—Å—è –ø–æ–¥–æ–∂–¥–∞—Ç—å...',
                     icon='üêå')
        
        model = WhisperModel(
                            model_size_or_path=selected_model_path,
                            device=local_device,
                            compute_type=selected_compute_type,
                            num_workers=4,
                            local_files_only=True
                            )

    with st.spinner('üî¨ –ü–µ—Ä–≤–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞. –ú–∏–Ω—É—Ç–∫—É...'):
        segments, info = model.transcribe(audio=str(uploaded_file_path),
                                      beam_size=5)

    st.write(f"–Ø–∑—ã–∫ —Ä–µ—á–∏: {info.language} —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é {info.language_probability}")

    st.write(f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ —Å–µ–∫—É–Ω–¥–∞—Ö: {info.duration}")

    progress_text = '‚è≥ –ò–¥—ë—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∞—É–¥–∏–æ'
    
    segments_bar = st.progress(0, text=progress_text)
    
    with st.expander('üìú –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —Ç–µ–∫—Å—Ç–∞'):
        for segment in segments:
            st.write("[%.2fs -> %.2fs] %s" % (segment.start, segment.end, segment.text))
            curr_bar_val = min(segment.end / info.duration, 1.0)
            segments_bar.progress(curr_bar_val, text=progress_text)

        time_total = time.time() - time_start

        st.markdown(
        """
        <style>
            .stProgress > div > div > div > div {
                background-color: green;
            }
        </style>""",
        unsafe_allow_html=True,
                )

    with st.expander('üõ† –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è'):
        st.markdown(f'*–û–±—â–µ–µ –≤—Ä–µ–º—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏*: {round(time_total)} —Å.')
